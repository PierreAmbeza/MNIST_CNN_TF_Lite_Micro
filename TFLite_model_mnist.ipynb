{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST-CNN-TFLite Micro\n",
    "\n",
    "Dans un précédent notebook, nous avons créer un modèle capable de prédire le chiffre écrit dans une image du dataset **MNIST** et converti ce modèle en version **TFLite**. Nous allons donc tester dans ce notebook la précision de ces modèles convertis par rapport au modèle d'origine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer une fonction **evaluate_model** qui permettra de faire les prédictions de nos modèles convertis et de calculer la précision de ces derniers. Enfin, nous comparons cette précision avec celle du modèle d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 176us/sample - loss: 0.0513 - accuracy: 0.9832\n",
      "Restored model, accuracy: 98.32%\n",
      "TFLite model accuracy: 98.32\n",
      "TFLite Quantized model accuracy: 98.33\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an interpreter for each model\n",
    "mnist_model = tf.lite.Interpreter('mnist_model.tflite')\n",
    "mnist_model_quantized = tf.lite.Interpreter('mnist_model_quantized.tflite')\n",
    "# Allocate memory for each model\n",
    "mnist_model.allocate_tensors()\n",
    "mnist_model_quantized.allocate_tensors()\n",
    "#Normalize test data\n",
    "\n",
    "\n",
    "#Compute accuracy for converted models\n",
    "def evaluate_model(interpreter):\n",
    "\n",
    "    # Create arrays to store the results\n",
    "    mnist_model_predictions = []\n",
    "\n",
    "    # Run each model's interpreter for each value and store the results in arrays\n",
    "    for i in x_test:\n",
    "    \n",
    "        input_details = interpreter.get_input_details()\n",
    "        i = np.expand_dims(i, axis= 0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_details[0]['index'], i)\n",
    "        interpreter.invoke()\n",
    "        output_details = interpreter.get_output_details()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        mnist_model_predictions.append(np.argmax(output_data))\n",
    "\n",
    "    count = 0\n",
    "    for j in range(len(mnist_model_predictions)):\n",
    "        if mnist_model_predictions[j] == y_test[j]:\n",
    "            count+=1\n",
    "    count = 100 * count / len(mnist_model_predictions)\n",
    "    return count\n",
    "\n",
    "new_model = tf.keras.models.load_model('mnist_model_origin')\n",
    "\n",
    "loss, acc = new_model.evaluate(x_test,  y_test)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n",
    "print(\"TFLite model accuracy: {:5.2f\".format(evaluate_model(mnist_model)))\n",
    "print(\"TFLite Quantized model accuracy:\", evaluate_model(mnist_model_quantized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que la précision des modèles convertis est égale ou presque à celle du modèle d'origine.\n",
    "\n",
    "Désormais, nous pouvons regarder la taille de chacun de nos modèles pour se rendre compte du gain en taille obtenu suite à la conversion en **TF Lite**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic model is 724440 bytes\n",
      "Quantized model is 186848 bytes\n",
      "Ratio between basic_model and quantized model is 3\n",
      "Original model is 1604174 bytes\n",
      "Ratio between basic_model and quantized model is 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#Compare size of converted models with origina model\n",
    "basic_model_size = os.path.getsize(\"mnist_model.tflite\")\n",
    "print(\"Basic model is %d bytes\" % basic_model_size)\n",
    "quantized_model_size = os.path.getsize(\"mnist_model_quantized.tflite\")\n",
    "print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
    "ratio = basic_model_size / quantized_model_size\n",
    "print(\"Ratio between basic_model and quantized model is %d\" % ratio)\n",
    "original_model_size = os.path.getsize(\"mnist_model_origin/saved_model.pb\")+os.path.getsize(\"mnist_model_origin/variables/variables.data-00000-of-00001\")+os.path.getsize(\"mnist_model_origin/variables/variables.index\")\n",
    "print(\"Original model is %d bytes\" % original_model_size)\n",
    "ratio = original_model_size / basic_model_size\n",
    "print(\"Ratio between basic_model and quantized model is %d\" % ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que le modèle d'origine fait 1,6 Mo environ. Le modèle **TF Lite** non quantifié est deux fois plus petit avec 700 Ko environ et le modèle **TF Lite** quantifié est quant à lui 3 fois plus petit que le modèle non quantifié et fait environ 180 Ko.\n",
    "\n",
    "Maintenant nous allons convertir les deux modèles **TF Lite** en modèles **TF Lite Micro** à l'aide de la commande **xxd**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!xxd -i mnist_model_quantized.tflite > mnist_model_quantized.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!xxd -i mnist_model.tflite > mnist_model.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ajoutons également une fonction permettant de créer un fichier **.h** comportant les données de test et que nous pourrons utiliser pour faire les prédictions avec **TF Lite Micro**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def write_test_data_header(file_name, x, y, n_values):\n",
    "  \"\"\"\n",
    "  Function to write a c header file containing a set of test input and output\n",
    "  data for this classification model\n",
    "  :param file_name: name of the header file to create\n",
    "  :param x: input data numpy array\n",
    "  :param y: output data numpy array, first dimension much match above\n",
    "  :return: Nothing\n",
    "  \"\"\"\n",
    "\n",
    "  with open(file_name, \"w\") as header:\n",
    "    header.write(\"// MNIST test data\\n\\n\")\n",
    "\n",
    "    header.write(\"int mnistSampleCount = %d;\\n\\n\" % n_values)\n",
    "\n",
    "    header.write(\"float mnistInput[%d][784] = {\\n\" % n_values)\n",
    "    for i in range(n_values):\n",
    "      if i != 0:\n",
    "        header.write(\",\\n\")\n",
    "      header.write(\"{ \")\n",
    "      row = x[i].reshape(1, 784).astype(np.int)\n",
    "      np.savetxt(header, row, delimiter=', ', newline='', fmt='%d')\n",
    "      header.write(\" }\")\n",
    "    header.write(\"};\\n\\n\")\n",
    "\n",
    "    header.write(\"int mnistOutput[%d] = { \" % n_values)\n",
    "    np.savetxt(header,\n",
    "               y[0:n_values].reshape(1, n_values),\n",
    "               delimiter=', ',\n",
    "               newline='',\n",
    "               fmt='%d')\n",
    "    header.write(\" };\\n\")\n",
    "\n",
    "write_test_data_header(\"mnist_test_data.h\", x_test, y_test, 50)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taille du fichier de test est de 118056 octets\n"
     ]
    }
   ],
   "source": [
    "#model_test_size = os.path.getsize(\"mnist_test_data.h\")\n",
    "#print(\"La taille du fichier de test est de %d octets\" % model_test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
